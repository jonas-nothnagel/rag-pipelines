{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.builders import PromptBuilder, AnswerBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.evaluators import ContextRelevanceEvaluator, FaithfulnessEvaluator, SASEvaluator\n",
    "from haystack.evaluation import EvaluationRunResult\n",
    "from haystack.components.converters import MarkdownToDocument\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.utils import Secret\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from openai import BadRequestError\n",
    "from getpass import getpass\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "generator_openai = OpenAIGenerator(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "if \"HF_API_KEY\" not in os.environ:\n",
    "    os.environ[\"HF_API_KEY\"] = getpass(\"Enter HF API key:\")\n",
    "generator = HuggingFaceAPIGenerator(api_type=\"serverless_inference_api\",\n",
    "                                    api_params={\"model\": \"mistralai/Mistral-7B-v0.1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import test data\n",
    "# import data\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "\n",
    "def read_question_answers() -> Tuple[List[str], List[str]]:\n",
    "    with open(\"../data/evaluation/eval_data_no_image_pdf.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        questions = data[\"questions\"]\n",
    "        answers = data[\"ground_truths\"]\n",
    "    return questions, answers\n",
    "\n",
    "questions, answers = read_question_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_files = []\n",
    "for root, dirs, files in os.walk(\"../data/processed_files\"):\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.md'):\n",
    "            markdown_files.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Pre-Processing: Document Loading, Indexing, Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document loading, indexing and embedding\n",
    "def indexing(embedding_model: str, chunk_size: int):\n",
    "\n",
    "    # specify document path\n",
    "    files_path = \"../data/processed_files\"\n",
    "\n",
    "    # specify type of document store - InMemory is the simplest one for prototyping. More advanced would be a VectorDatabase\n",
    "    document_store = InMemoryDocumentStore()\n",
    "\n",
    "    # define pre-processing pipeline\n",
    "    pipeline = Pipeline()\n",
    "    # markdown from already transformed PDF documents\n",
    "    pipeline.add_component(\"converter\", MarkdownToDocument())\n",
    "    #pipeline.add_component(\"converter\", PyPDFToDocument())\n",
    "    pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "    pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"sentence\", split_length=chunk_size, split_overlap=25))  # splitting by word\n",
    "    pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP))\n",
    "    pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(embedding_model))\n",
    "    pipeline.connect(\"converter\", \"cleaner\")\n",
    "    pipeline.connect(\"cleaner\", \"splitter\")\n",
    "    pipeline.connect(\"splitter\", \"embedder\")\n",
    "    pipeline.connect(\"embedder\", \"writer\")\n",
    "    markdown_files = []\n",
    "    for root, dirs, files in os.walk(\"../data/processed_files\"):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.md'):\n",
    "                markdown_files.append(os.path.join(root, file))\n",
    "    pipeline.run({\"converter\": {\"sources\": markdown_files}})\n",
    "\n",
    "    return document_store, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting markdown files to Documents: 100%|██████████| 9/9 [00:00<00:00, 10.99it/s]\n",
      "Batches: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# let's index and embedd such that the RAG can simply access the documentstore\n",
    "document_store, pipeline = indexing(\"sentence-transformers/all-mpnet-base-v2\", 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
