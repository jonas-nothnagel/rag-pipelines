{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/miniconda3/envs/haystack-rag/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.converters import PyPDFToDocument\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack.components.preprocessors import DocumentCleaner, DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.document_stores.types import DuplicatePolicy\n",
    "from haystack.components.builders import PromptBuilder, AnswerBuilder\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.retrievers import InMemoryEmbeddingRetriever\n",
    "from haystack.components.evaluators import ContextRelevanceEvaluator, FaithfulnessEvaluator, SASEvaluator\n",
    "from haystack.evaluation import EvaluationRunResult\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from openai import BadRequestError\n",
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "generator = OpenAIGenerator(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import test data\n",
    "# import data\n",
    "import json\n",
    "from typing import Tuple, List\n",
    "\n",
    "def read_question_answers() -> Tuple[List[str], List[str]]:\n",
    "    with open(\"../data/evaluation/eval_data_no_image_pdf.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        questions = data[\"questions\"]\n",
    "        answers = data[\"ground_truths\"]\n",
    "    return questions, answers\n",
    "\n",
    "questions, answers = read_question_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Pre-Processing: Document Loading, Indexing, Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document loading, indexing and embedding\n",
    "def indexing(embedding_model: str, chunk_size: int):\n",
    "\n",
    "    # specify document path\n",
    "    files_path = \"../data/evaluation/eval_documents\"\n",
    "\n",
    "    # specify type of document store\n",
    "    document_store = InMemoryDocumentStore()\n",
    "\n",
    "    # define pre-processing pipeline\n",
    "    pipeline = Pipeline()\n",
    "    pipeline.add_component(\"converter\", PyPDFToDocument())\n",
    "    pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "    pipeline.add_component(\"splitter\", DocumentSplitter(split_length=chunk_size))  # splitting by word\n",
    "    pipeline.add_component(\"writer\", DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP))\n",
    "    pipeline.add_component(\"embedder\", SentenceTransformersDocumentEmbedder(embedding_model))\n",
    "    pipeline.connect(\"converter\", \"cleaner\")\n",
    "    pipeline.connect(\"cleaner\", \"splitter\")\n",
    "    pipeline.connect(\"splitter\", \"embedder\")\n",
    "    pipeline.connect(\"embedder\", \"writer\")\n",
    "    pdf_files = [files_path+\"/\"+f_name for f_name in os.listdir(files_path)]\n",
    "    pipeline.run({\"converter\": {\"sources\": pdf_files}})\n",
    "\n",
    "    return document_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
